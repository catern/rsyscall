* design
I guess we talk about fork here?
And all the different tasks?
ssh, persistent, etc?
well maybe not all of them, perhaps just ssh and fork?

no maybe just fork?
and we can mention ssh?

yeah we'll do some forking, some execing,
some namespaces,
and mention ssh and the rest at the end.
** hmm
   should really show that we have complete generality in,
   doing things before exec.
   
   maybe do a dup3 explicitly?
   even though I don't really use those...
   yeah sure dup3 explicitly

   for familiarity's sake

   let's call it dup2 instead of dup3 too lol

   since dup2 is more familiar

   ok so maybe we can do a cat with a pipe?
   pipes are ugly to create though,
   I don't want to scare them away...

   oh I could use open_channels, sure let's do that.

   ok that seems good, we'll use which to find cat,
   open_channels to make a channel,
   dup2 to set 'em up,
   and exec away.

   i'll note that the open_channels can happen either in the parent or in the child

   oh that's not strictly true, if we do it in the parent then we need a,
   um,
   for_task call so that the handle gets inherited across unshare_files

   hmmmm it would be nice if with unshare_files,
   we just passed unshare(CLONE.FILES) instead.
   cuz, naming it unshare_files is annoying.

   I could even call it on the task instead of the thread.
* tutorial

In rsyscall, `Thread` is the name of a class which contains several objects within it,
together allowing system calls to be executed on the context of a specific process,
as well as creating new `Thread`s mapping to new processes by various means.

The operations that can be done using a single `Thread` are covered in some detail
in the [[file:single_threaded.org][single-threaded tutorial]].
In this tutorial, we consider the creation and use of multiple threads.

Each `Thread` is tied to a separate Linux process which is created and destroyed separately,
but these processes may share many details,
including their address space and file descriptor table.

No Python code runs in threads;
the only place that Python code runs is in the main Python interpreter process.
Threads are only contexts within which to execute syscalls as Python code wishes.
* Initial example
Here is an example program:
#+BEGIN_SRC python
from rsyscall import Thread, Path
from rsyscall.sys.wait import W, CLD

# GNU hello is a program which prints "Hello, world!"
async def example1(thr: Thread, hello_path: Path) -> None:
    child = await thr.fork()
    child_process = await child.execve(hello_path, ['hello'])
    event = await child_process.waitpid(W.EXITED)
    if not (event.code == CLD.EXITED and event.exit_status == 0):
        raise Exception("GNU hello exited uncleanly :(")
#+END_SRC

This function creates a child process running GNU hello,
waits for hello to exit,
and throws if it exited uncleanly. 

We receive a thread as an argument;
we'll consider where the original thread comes from later on.

We receive a Path as an argument as well;
this should be the path to the "hello" binary from the GNU hello package.

We create a new `Thread` using `thr.fork()`.
What we get back is in fact a `ChildThread`;
a `ChildThread` is a `Thread` with the additional knowledge that it's the child of one of our other threads.
Knowing that, we can call `exec` on the `ChildThread` and monitor the resulting child process.
A bare `Thread` does not have the ability to (safely) call `execve`,
because there's no other `Thread` that is its parent and is able to monitor it.

`fork` here is not using any special control flow;
this is a normal Python function, which returns exactly once.
Remember that Python code does not execute in threads;
when we call `fork`, we get back a new context to execute syscalls in.

When we call `child.execve(hello)`,
the kernel stops the code currently running in the `child` thread,
loads the "hello" binary into the `child` thread,
and starts running "hello".

The `Thread` interface will no longer work;
the process is now under the control of GNU hello.
But, the `Thread` interface helpfully returns, as its final act,
a `ChildProcess` which we can use to monitor the process,
even if we can no longer control it.

We call `waitpid(W.EXITED)` on the child process,
to wait for the child process to exit and receive its exit event.

Then we check that the child process exited cleanly, and throw if it did not.
* the initial, local thread
Where does the first thread come from?

Every rsyscall program starts out with one thread available to it:
The local thread.
The local thread can be imported from `rsyscall.tasks.local`, as follows:
#+BEGIN_SRC python
from rsyscall.tasks.local import thread as local_thread
#+END_SRC

Typically, a program will be written taking a `Thread` as a function argument all the way through,
and only in the main function will the local thread be imported and passed as an argument.
This allows for programs to work for any thread,
which allows for substantial flexibility about the process and system that the program actually operates on.
* fork
The `fork` method is the normal way to create new threads.
It is the only high-level way to create a child thread,
which is a thread that is the child of one of our other existing threads,
and can therefore be monitored even if we call exec on the child thread.

A thread created with `fork` starts out sharing all namespaces with its parent thread.
This includes the file descriptor table and the address space.
Changes in the parent thread affect the child thread, and vice versa.
(This is not the behavior of the POSIX `fork` function,
but we reused the name because it's nice to see the fork/exec pattern.)

Since the file descriptor table is shared,
we can open files in the parent and use them in the child,
or vice versa.

This is especially useful when the child does not share other namespaces;
for example, the child and its parent might be in different network namespaces,
but the child can receive sockets from the parent's network namespace
since they share the file descriptor table.

If we want to change some open file descriptors only before execing,
(replace stdin/stdout/stderr or unset CLOEXEC, for example),
we will typically want to do this only in the child.

To do that, we first call `unshare(UnCLONE.FILES)` on the child.
(As discussed in the single-threaded tutorial,
names of constants follow the pattern of Linux headers,
and are sometimes prefixed to improve type safety
when subsets of an enum are used by different syscalls)

As documented in [[http://man7.org/linux/man-pages/man2/unshare.2.html][man 2 unshare]], this creates a new file descriptor table for the thread it's called on.

Only file descriptors owned by the thread are copied into the new file descriptor table.
File descriptors are owned by the thread that first created them,
and ownership can be transferred between threads in the same file descriptor table using `fd.move(thread.task)`.
Note that since `move` is purely a Python-level bookkeeping operation,
`move` is not an async operation and does not need to be awaited.
`move` invalidates the file descriptor object it is called on,
and returns a new file descriptor object with the new ownership,
which should be used afterwards.

After the unshare,
we're free to mutate the file descriptors as we wish
without interfering with other threads.
* unshare example
#+BEGIN_SRC python
from rsyscall import Thread
from rsyscall.sched import UnCLONE

async def example2(thr: Thread, cat_path: Path, pair: Socketpair) -> None:
    ## launch a child thread
    child = await thr.fork()
    ## replace the child's stdin and stdout with pair.first
    # move ownership of pair.first to the child task
    stdinout = pair.first.move(child.task)
    # unshare - only child-owned file descriptors remain in the new fd table
    await child.unshare(UnCLONE.FILES)
    await stdinout.dup2(child.stdin)
    await stdinout.dup2(child.stdout)
    ## exec cat on the child thread
    child_process = await child.execve(cat_path, ['cat'])
    ## write and read some data sent through cat
    written, _ = await pair.second.write(await thr.ram.ptr(b"hello world"))
    read, _ = await pair.second.read(written)
    print(await read.read())
    ## wait for cat to exit
    # close the other end of cat's stdin/stdout
    await pair.second.close()
    # cat gets EOF and exits cleanly.
    event = await child_process.waitpid(W.EXITED)
    if not (event.code == CLD.EXITED and event.exit_status == 0):
        raise Exception("cat exited uncleanly :(")
#+END_SRC

This function creates a subprocess running cat,
writes "hello world" to cat,
reads that same data back from cat,
waits for cat to exit,
and throws if it exited uncleanly.

As in our original example, we receive a thread and path as arguments,
and immediately fork off a child.

We also receive a Socketpair, produced elsewhere by a call to the socketpair() system call.
The Socketpair class contains the two file descriptor ends of the socketpair in the "first" and "second" fields.
Note that a socketpair is bidirectional, unlike a pipe,
so we can use just one end for both stdin and stdout.

We move ownership of pair.first into the child thread with `pair.first.move(child.task)`;
this invalidates `pair.first` and returns a new file descriptor object to use, `stdinout`.

We unshare the file descriptor table,
so that we can overwrite the child's stdin and stdout without having effects on anyone else.

We use `dup2` to actually do the replacement of stdin and stdout;
`dup2` replaces the file descriptor passed as its argument (`child.stdin` and `child.stdout`)
with a copy of the file descriptor it's called as a method on (`stdinout`).

We perform the exec, getting back a child process we can monitor.

We read and write from `pair.second` as explained in the [[file:single_threaded.org][single-threaded tutorial]].

We close `pair.second` so that cat gets EOF,
and wait for it to exit cleanly.
* process cleanup and pid namespaces
Our direct children will be killed on our death,
which includes all our threads and any child processes we've exec'd.

Many child processes will be running programs which don't spawn their own children.
Some programs spawn children, but correctly clean them up if they die.
These two classes are fine and will be automatically cleaned up without any effort on our part.

Unfortunately, there are also many programs which spawn children and don't clean them up if they die.
We can clean up after such programs by using pid namespaces.

This is not essential functionality for most users;
we are examining this as a demonstration of the flexibility of the thread model.

#+BEGIN_SRC python
async def example3(thr: Thread) -> None:
    pass
#+END_SRC

* TODO do something fancier to show we're totally without restrictions
  We can open a socket in a net namespace and pass it out.

  We can make pid namespaces, mount namespaces, all that stuff.

  Hmmm actually I think that's implied maybe?

  No, we do need to show something container-y at least.
  Using namespaces.
  I think pid namespaces would be a good one.

  It doesn't exploit our fd-table sharedness, 
  but, in retrospect,
  maybe the fd table stuff would concern people.

  OK so yeah pid namespaces.

  This also gives us a chance to talk about threads dying.
  ANd getting cleaned up
* do fancier namespace stuff?
  Usage of namespaces would be cool.

  ok so one tricky thing is that, actually doing a netns thing requires setting up loopback,
  which is tricky.

  pid namespaces are easier
  and useful too

  ok so we can do, like, an unshare_pid,
  then start some things in the namespace?

  hmm that doesn't actually use our power though.

  the tun would do it

  but the tun is too unknown

  what about mount namespaces?

  oh maybe I should just have a function that sets up loopback in the netns.
* TODO unshare fds?
* TODO namespaces/container stuff?
  pid namespace probably - since that's the most useful one?

  or maybe some net namespace stuff? since it's cool to be able to act as root?

  yeah something with net namespace would be neat.
  that's a truly powerful thing.

  well I mean let's focus on actually educating, not blowing minds
* TODO ssh?
