In rsyscall, `Thread` is the name of a class which contains several objects within it,
together allowing system calls to be executed on the context of a specific process,
as well as creating new `Thread`s mapping to new child processes.

The operations that can be done using a single `Thread` are covered in some detail
in the [[file:single_threaded.org][single-threaded tutorial]].
In this tutorial, we consider the creation and use of multiple threads.

Each `Thread` is tied to a separate Linux process which is created and destroyed separately,
but these processes may share many details,
including their address space and file descriptor table.

No Python code runs in threads;
the only place that Python code runs is in the main Python interpreter process.
Threads are only contexts within which to execute syscalls as Python code wishes.
* Initial example
Here is an example program:
#+BEGIN_SRC python
from rsyscall import Thread, Path
from rsyscall.sys.wait import W, CLD

# GNU hello is a program which prints "Hello, world!"
async def example1(thr: Thread, hello_path: Path) -> None:
    child = await thr.fork()
    child_process = await child.execve(hello_path, ['hello'])
    event = await child_process.waitpid(W.EXITED)
    if not (event.code == CLD.EXITED and event.exit_status == 0):
        raise Exception("GNU hello exited uncleanly :(")
#+END_SRC

This function creates a child process running GNU hello,
waits for hello to exit,
and throws if it exited uncleanly. 

We receive a thread as an argument;
we'll consider where the original thread comes from later on.

We receive a Path as an argument as well;
this should be the path to the "hello" binary from the GNU hello package.

We create a new `Thread` using `thr.fork()`.
What we get back is in fact a `ChildThread`;
a `ChildThread` is a `Thread` with the additional knowledge that it's the child of one of our other threads.
Knowing that, we can call `exec` on the `ChildThread` and monitor the resulting child process.
A bare `Thread` does not have the ability to (safely) call `execve`,
because there's no other `Thread` that is its parent and is able to monitor it.

`fork` here is not using any special control flow;
this is a normal Python function, which returns exactly once.
Remember that Python code does not execute in threads;
when we call `fork`, we get back a new context to execute syscalls in.

When we call `child.execve(hello)`,
the kernel stops the code currently running in the `child` thread,
loads the "hello" binary into the `child` thread,
and starts running "hello".

The `Thread` interface will no longer work;
the process is now under the control of GNU hello.
But, the `Thread` interface helpfully returns, as its final act,
a `ChildProcess` which we can use to monitor the process,
even if we can no longer control it.

We call `waitpid(W.EXITED)` on the child process,
to wait for the child process to exit and receive its exit event.

Then we check that the child process exited cleanly, and throw if it did not.
* the initial, local thread
Where does the first thread come from?

Every rsyscall program starts out with one thread available to it:
The local thread.
The local thread can be imported from `rsyscall.tasks.local`, as follows:
#+BEGIN_SRC python
from rsyscall.tasks.local import thread as local_thread
#+END_SRC

Typically, a program will be written taking a `Thread` as a function argument all the way through,
and only in the main function will the local thread be imported and passed as an argument.
This allows for programs to work for any thread,
which allows for substantial flexibility about the process and system that the program actually operates on.
* fork
The `fork` method is the normal way to create new threads.
It is the only high-level way to create a child thread,
which is a thread that is the child of one of our other existing threads,
and can therefore be monitored even if we call exec on the child thread.

A thread created with `fork` starts out sharing all namespaces with its parent thread.
This includes the file descriptor table and the address space.
Changes in the parent thread affect the child thread, and vice versa.
(This is not the behavior of the POSIX `fork` function,
but we reused the name because it's nice to see the fork/exec pattern.)

Since the file descriptor table is shared,
we can open files in the parent and use them in the child,
or vice versa.

This is especially useful when the child does not share other namespaces;
for example, the child and its parent might be in different network namespaces,
but the child can receive sockets from the parent's network namespace
since they share the file descriptor table.

If we want to change some open file descriptors only before execing,
(replace stdin/stdout/stderr or unset CLOEXEC, for example),
we will typically want to do this only in the child.

To do that, we first call `unshare(UnCLONE.FILES)` on the child.
(As discussed in the single-threaded tutorial,
names of constants follow the pattern of Linux headers,
and are sometimes prefixed to improve type safety
when subsets of an enum are used by different syscalls)

As documented in [[http://man7.org/linux/man-pages/man2/unshare.2.html][man 2 unshare]], this creates a new file descriptor table for the thread it's called on.

Only file descriptors owned by the thread are copied into the new file descriptor table.
File descriptors are owned by the thread that first created them,
and ownership can be transferred between threads in the same file descriptor table using `fd.move(thread.task)`.
Note that since `move` is purely a Python-level bookkeeping operation,
`move` is not an async operation and does not need to be awaited.
`move` invalidates the file descriptor object it is called on,
and returns a new file descriptor object with the new ownership,
which should be used afterwards.

After the unshare,
we're free to mutate the file descriptors as we wish
without interfering with other threads.
* unshare example
#+BEGIN_SRC python
from rsyscall import Thread
from rsyscall.sched import UnCLONE

async def example2(thr: Thread, cat_path: Path, pair: Socketpair) -> None:
    ## launch a child thread
    child = await thr.fork()
    ## replace the child's stdin and stdout with pair.first
    # move ownership of pair.first to the child task
    stdinout = pair.first.move(child.task)
    # unshare - only child-owned file descriptors remain in the new fd table
    await child.unshare(UnCLONE.FILES)
    # dup2 unsets the cloexec flag so these fds are inherited across exec
    await stdinout.dup2(child.stdin)
    await stdinout.dup2(child.stdout)
    ## exec cat on the child thread
    child_process = await child.execve(cat_path, ['cat'])
    ## write and read some data sent through cat
    written, _ = await pair.second.write(await thr.ram.ptr(b"hello world"))
    read, _ = await pair.second.read(written)
    print(await read.read())
    ## wait for cat to exit
    # close the other end of cat's stdin/stdout
    await pair.second.close()
    # cat gets EOF and exits cleanly.
    event = await child_process.waitpid(W.EXITED)
    if not (event.code == CLD.EXITED and event.exit_status == 0):
        raise Exception("cat exited uncleanly :(")
#+END_SRC

This function creates a subprocess running cat,
writes "hello world" to cat,
reads that same data back from cat,
waits for cat to exit,
and throws if it exited uncleanly.

As in our original example, we receive a thread and path as arguments,
and immediately fork off a child.

We also receive a Socketpair, produced elsewhere by a call to the socketpair() system call.
The Socketpair class contains the two file descriptor ends of the socketpair in the "first" and "second" fields.
Note that a socketpair is bidirectional, unlike a pipe,
so we can use just one end for both stdin and stdout.

We move ownership of pair.first into the child thread with `pair.first.move(child.task)`;
this invalidates `pair.first` and returns a new file descriptor object to use, `stdinout`.

We unshare the file descriptor table,
so that we can overwrite the child's stdin and stdout without having effects on anyone else.

We use `dup2` to actually do the replacement of stdin and stdout;
`dup2` replaces the file descriptor passed as its argument (`child.stdin` and `child.stdout`)
with a copy of the file descriptor it's called as a method on (`stdinout`).

We perform the exec, getting back a child process we can monitor.

We read and write from `pair.second` as explained in the [[file:single_threaded.org][single-threaded tutorial]].

We close `pair.second` so that cat gets EOF,
and wait for it to exit cleanly.
* process cleanup and pid namespaces
Our direct children will be killed on our death,
which includes all our threads and any child processes we've exec'd.

Many child processes will be running programs which don't spawn their own children.
Some programs spawn children, but correctly clean them up if they die.
These two classes are fine and will be automatically cleaned up without any effort on our part.

Unfortunately, there are also many programs which spawn children and don't clean them up if they die,
leaving them behind as orphans on the system.
We can clean up after such programs by using pid namespaces.

#+BEGIN_SRC python
from rsyscall import Thread, Bytes
from rsyscall.sched import UnCLONE
from rsyscall.fcntl import F
from rsyscall.sys.wait import W, CLD

async def example3(thr: Thread, sh_path: Path, pipe: Pipe) -> None:
    # create new pid namespace, with init as one of our threads
    init = await thr.fork(CLONE.NEWUSER|CLONE.NEWPID)
    # create a new child inside the pid namespace
    child = await init.fork()
    # pass down the write-end of the pipe to the child;
    # the write-end of the pipe will only be open inside the child.
    child_fd = pipe.write.move(child.task)
    await child.unshare(UnCLONE.FILES)
    # unset the cloexec flag so this fd is inherited across exec
    await child_fd.fcntl(F.SETFD, 0)
    # exec into sh to leave "sleep inf" running forever as an orphan.
    # as long as "sleep inf" runs, the write-end of the pipe is kept open.
    child_process = await child.execve(sh_path, ['sh', '-c', '{ sleep inf & } &'])
    event = await child_process.waitpid(W.EXITED)
    if not (event.code == CLD.EXITED and event.exit_status == 0):
        raise Exception("sh exited uncleanly :(")
    # there's now a "sleep inf" orphan running forever inside the pid namespace.
    # exit the init process to shut down the pid namespace 
    await init.exit(0)
    # we read the pipe and get an EOF, since the write-end has been closed.
    read, _ = await pipe.read.read(await thr.ram.malloc(Bytes, 1))
    if read.size() != 0:
        raise Exception("unexpectedly actually read something?!??")
#+END_SRC

This function creates a pid namespace,
passes down the write end of a pipe to an orphaned "sleep inf" process,
shuts down the pid namespace,
and reads an EOF from the read-end of the pipe, indicating that the "sleep inf" process is dead.

We first spawn a new pid namespace by passing CLONE.NEWPID to fork;
we need to also pass CLONE.NEWUSER to create a user namespace to gain the privileges required to create a pid namespace.
See [[http://man7.org/linux/man-pages/man7/namespaces.7.html][man 7 namespaces]] for more in-depth documentation about namespaces.

The new thread is the init process in the pid namespace.
We fork again from init to create a useful child in the namespace.

We move ownership of the write-end of the pipe to the child thread,
unshare the file descriptor table,
and unset the CLOEXEC flag so that the write-end of the pipe will be inherited across exec into "sleep inf".

We exec a sh program from the child thread,
and wait for the resulting child process to terminate.
Once it's completed, we know that "sleep inf" is left alive inside the pid namespace.

We exit the init thread to shut down the pid namespace.
This kills the "sleep inf" process inside the pid namespace.

Since the "sleep inf" process is dead,
and it held the only copy of the write-end of the pipe,
the write-end of the pipe is now closed.
Since the write-end of the pipe is closed,
we get an EOF when we read from the read-end of the pipe.
* TODO helpers
** exec, Command
   exec takes Commands;
   Commands are a name + some args + some environment variables.
#+BEGIN_SRC python
await child.exec(sh.args('-c', 'echo $HELLO').env(HELLO="hello world"))
#+END_SRC
** environ: Environment
   sh, which

#+BEGIN_SRC python
await child.exec(child.environ.sh('-c', 'true'))
await child.exec(await child.environ.which('hello'))
#+END_SRC
** check
   Waits for the child process to exit, then throws an exception if it didn't exit cleanly.

#+BEGIN_SRC python
await (await child.exec(await child.environ.which('hello'))).check()
#+END_SRC

* TODO ssh? other thread styles?
  Showing the other kinds of threads might be too much.
  Might blow their minds a little too much.
  That might be for a third tutorial.

  And, to prevent people from immediately jumping to "advanced multi-threading",
  we'll only link it from the end of this tutorial.
